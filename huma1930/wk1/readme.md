# Week 1 - What is Technology?

## New vs Old

New tech and old tech are both tech: both a well and smartphones are technologies.

## Two views on technology

1. **Instrumental Theory**: instrument that humans use as means to their ends
    - Prominent in Engineering point of view
    - Value-neutral

2. **Anthropological Theory**: technology as parts of distinctively human activities
    - Anthropologists and social scientists

- Combining both: "the instrumental and anthropological definition of technology", technologies as means to ends within human activities (Heidegger 1977)

## The view on robots

- Joanna Bryson: computer scientist and roboticist ➡ ethics professor
- Book "_Robots Should Be Slaves_"
- Robot as a tool: servants/slaves of humans, can be bought or sold
- Should not create machines with humanlike qualities
  - e.g., experience suffering, sensitive in ways like a human
  - So that we don't have moral responsibilities / duties towards them
    - Example: robot Sophia, _humanoid_ robot, given honorary citizenship of Saudi Arabia - Face and imitate human speech
    - Problematic: treated as if it were a human, but can be turned on and off (?)

> Bryson has **normative version of instrumental theory of technology**

- _normative_: what we should and should not do;
- _instrumental_: tech as tools

## "Post-Phenomenology"

Phenomenology: reflection on life start with real life phenomena instead of abstract philosophical theories

**Post**-phenomenology: how tech shape how we experience reality, ourselves, and what we are able to do or aim for
    - Don Ihde, Bruno Latour, Peter-Paul Verbeek

Sociologists and philosophers disagree with instrumental theory of tech:

- Analyze human practices involving technologies
- How tech around us affects us
- Tech are not completely value-neutral

## Mediation theory

Technologies as a medium between us and what we perceive and what we do

- Shapes our perception and experience (of the world and ourselves)
  - Visual experience when wearing glasses our looking at photos
  - What we pay attention to in life shaped by tech we use
    - Algorithmic recommendations

- Shapes what <mark>(we see ourselves)</mark> we can do and how we do it
  - e.g., airplanes → can travel far in short time
    - nobody think about this before planes existed
  - social media changes how we communicate
    - online anonymity → dare speaking up; abusive language
  - what something _is_
    - a river, water source or for energy source
    - extreme: nature viewed as means to human ends; not end itself

Post-phenomenologists argue that:

1. Technology is **not** value neutral because they shape how we value things around us
2. Tech has (un)intended "scripts" → hints or forces people to behave in certain ways
    - paper cups, speed bumps, seatbelt alerts, etc.
3. **The assemblage**: people + technology can do things neither alone can
    - gunman → have gun and more inclined to shoot → changes behavior
    - "you are what you eat"; "you are what tech you use" → not separate

## Persons and Things

_Groundwork for the Metaphysics of Morals_ (Immanuel Kant)

- _Persons_: Can <mark>think</mark> and <mark>act</mark>. ends-in-themselves.
  - responsible for own actions, member of moral community
- _Things_: Everything else
  - only valuable relative to wishes of persons
  - should never create tech that is "end-in-itself"

However, some tech ethicists argue that some tech **can** think and act like persons do

### "Autonomous" Machines as Moral Agents

> can operate without human input, make moral decisions

- Self-driving cars, autonomous weapons

"Machine ethics" → Moral machines?

- different kind of moral agent (Luciano Floridi)
  - not responsible for self decisions, unlike persons
  - responsibility gap: neither machine or person created it responsible

- faces of moral responsibility (Daniel Tigard)
  - some tech is partial responsible
  - far from instrumental view of technology

### As Moral Patients

> We can have obligations or duties towards it, and how we treat it is a moral consideration

- _"Cruel to kick robot dog?"_
  - Engineers kick Spot to show its stability → instrumental view
  - It is wrong to kick a dog, even robotic one → as a moral patient
- "Relational" theory of moral status ascriptions (Mark Coeckelbergh, David Gunkel)
  - what **relationship** should we hold with things around us?
    - Moral consideration? rights?
    - some farm animals get rights as pets and farm animals, how about robots?
- ethical behaviorism (John Danaher)
  - if it behaves like something with moral rights, we should give it that
  - e.g., indication of suffering, avoid things that would make it suffer
  - e.g., behave like a friend, chatting, treat it as a friend

## When We Notice Technology

- familiar technologies fade into the background
- becomes the lens we use to experience the world, take for granted
- only notice when stops working or not accustomed (new tech)
